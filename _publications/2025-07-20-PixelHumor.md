---
title: "Humor in Pixels: Benchmarking Large Multimodal Models Understanding of Online Comics"
collection: publications
category: conferences
permalink: /publication/2025-07-20-PixelHumor
excerpt: 'Evaluating humor and sequence comprehension in Large Multimodal Models with web comics.'
date: 2025-07-20
venue: 'Findings of the Association for Computational Linguistics (EMNLP 2025)'
authors: 'Yuriel Ryan*, Rui Yang Tan*, Kenny Tsu Wei Choo, Roy Ka-Wei Lee'
authors_note: '* co-first authors'
paperurl: 'https://aclanthology.org/2025.findings-emnlp.755/'
citation: |
  @inproceedings{ryan-etal-2025-humor,
      title = "Humor in Pixels: Benchmarking Large Multimodal Models Understanding of Online Comics",
      author = "Ryan, Yuriel  and
        Tan, Rui Yang  and
        Choo, Kenny Tsu Wei  and
        Lee, Roy Ka-Wei",
      editor = "Christodoulopoulos, Christos  and
        Chakraborty, Tanmoy  and
        Rose, Carolyn  and
        Peng, Violet",
      booktitle = "Findings of the Association for Computational Linguistics: EMNLP 2025",
      month = nov,
      year = "2025",
      address = "Suzhou, China",
      publisher = "Association for Computational Linguistics",
      url = "https://aclanthology.org/2025.findings-emnlp.755/",
      doi = "10.18653/v1/2025.findings-emnlp.755",
      pages = "14024--14050",
      ISBN = "979-8-89176-335-7",
      abstract = "Understanding humor is a core aspect of social intelligence, yet it remains a significant challenge for Large Multimodal Models (LMMs). We introduce PixelHumor, a benchmark dataset of 2,800 annotated multi-panel comics designed to evaluate LMMs' ability to interpret multimodal humor and recognize narrative sequences. Experiments with state-of-the-art LMMs reveal substantial gaps: for instance, top models achieve only 61{\\%} accuracy in panel sequencing, far below human performance. This underscores critical limitations in current models' integration of visual and textual cues for coherent narrative and humor understanding. By providing a rigorous framework for evaluating multimodal contextual and narrative reasoning, PixelHumor aims to drive the development of LMMs that better engage in natural, socially aware interactions."
  }
---

Understanding humor is a core aspect of social intelligence, yet it remains a significant challenge for Large Multimodal Models (LMMs). We introduce PixelHumor, a benchmark dataset of 2,800 annotated multi-panel comics designed to evaluate LMMs’ ability to interpret multimodal humor and recognize narrative sequences. Experiments with state-of-the-art LMMs reveal substantial gaps: for instance, top models achieve only 61% accuracy in panel sequencing, far below human performance. This underscores critical limitations in current models’ integration of visual and textual cues for coherent narrative and humor understanding. By providing a rigorous framework for evaluating multimodal contextual and narrative reasoning, PixelHumor aims to drive the development of LMMs that better engage in natural, socially aware interactions.